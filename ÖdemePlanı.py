import streamlit as st
import requests
from bs4 import BeautifulSoup
import re

def fetch_ad_details(url):
    """
    Verilen sahibinden.com URL'sinden ilan detaylarÄ±nÄ± Ã§ekmeyi dener.
    """
    try:
        # Sahibinden.com'un bot engellemesini aÅŸmak iÃ§in bir tarayÄ±cÄ± gibi davranÄ±yoruz.
        # 403 HatasÄ±nÄ± (Forbidden) aÅŸmak iÃ§in User-Agent ve diÄŸer baÅŸlÄ±klarÄ± gÃ¼ncelledik.
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36',
            'Accept-Language': 'tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Referer': 'https://www.sahibinden.com/', # Nereden geldiÄŸimizi belirtmek (ana sayfa)
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1', # HTTPS'e yÃ¼kseltme talebi
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status() # Hata varsa (404, 500 vb.) yakala
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        details = {
            "title": "BulunamadÄ±",
            "price": "BulunamadÄ±",
            "plate": None,
            "painted": [],
            "replaced": [],
            "description": "AÃ§Ä±klama bulunamadÄ±."
        }

        # Ä°lan BaÅŸlÄ±ÄŸÄ±
        title_tag = soup.find('h1', class_='classifiedDetailTitle')
        if title_tag:
            details['title'] = title_tag.get_text(strip=True)
            
        # Fiyat
        price_tag = soup.find('div', class_='classifiedInfo').find('h3')
        if price_tag:
            details['price'] = price_tag.get_text(strip=True).replace('TL', '').strip() + " TL"
            
        # Plaka (Genellikle "Teknik Ã–zellikler" veya "Ã–zellikler" listesinde olur)
        # Bazen satÄ±cÄ±lar plakayÄ± "BelirtilmemiÅŸ" olarak girer veya hiÃ§ girmez.
        properties_list = soup.select('div.classifiedProperties ul li')
        
        for item in properties_list:
            strong_tag = item.find('strong')
            if strong_tag and 'Plaka' in strong_tag.get_text():
                span_tag = item.find('span')
                if span_tag:
                    plate_text = span_tag.get_text(strip=True)
                    # "BelirtilmemiÅŸ", "YabancÄ± Plaka" gibi durumlarÄ± filtrele
                    if plate_text and "BelirtilmemiÅŸ" not in plate_text and "YabancÄ±" not in plate_text:
                        # PlakayÄ± temizle (Ã¶rn: 34 ABC 123 -> 34ABC123)
                        details['plate'] = re.sub(r'\s+', '', plate_text).upper()
                        break

        # --- YENÄ° BÃ–LÃœM: Boya/DeÄŸiÅŸen ve AÃ§Ä±klama ---
        
        # 1. Boya & DeÄŸiÅŸen Bilgisi
        # Sahibinden'in yapÄ±sÄ±: <h3>Boya & DeÄŸiÅŸen</h3>, sonra <ul><li><h4>BoyalÄ±..</h4><ul><li>...</li></ul></li><li><h4>DeÄŸiÅŸen..</h4><ul>...</ul></li></ul>
        paint_header = soup.find('h3', string=re.compile(r'Boya & DeÄŸiÅŸen'))
        if paint_header:
            main_ul = paint_header.find_next_sibling('ul')
            if main_ul:
                # BoyalÄ± ParÃ§alar
                boyali_li = main_ul.find('h4', string=re.compile(r'BoyalÄ± ParÃ§alar'))
                if boyali_li:
                    boyali_ul = boyali_li.find_next_sibling('ul')
                    if boyali_ul:
                        selected = boyali_ul.find_all('li', class_='selected')
                        details['painted'] = [li.get_text(strip=True) for li in selected]

                # DeÄŸiÅŸen ParÃ§alar
                degisen_li = main_ul.find('h4', string=re.compile(r'DeÄŸiÅŸen ParÃ§alar'))
                if degisen_li:
                    degisen_ul = degisen_li.find_next_sibling('ul')
                    if degisen_ul:
                        selected = degisen_ul.find_all('li', class_='selected')
                        details['replaced'] = [li.get_text(strip=True) for li in selected]

        if not details['painted']:
            details['painted'] = ["SatÄ±cÄ± tarafÄ±ndan belirtilmemiÅŸ."]
        if not details['replaced']:
            details['replaced'] = ["SatÄ±cÄ± tarafÄ±ndan belirtilmemiÅŸ."]

        # 2. Ä°lan AÃ§Ä±klamasÄ±
        description_div = soup.find('div', id='classifiedDescription')
        if description_div:
            # Metni al ve gereksiz boÅŸluklarÄ± temizle
            details['description'] = ' '.join(description_div.get_text(strip=True).split())
        
        # --- BÄ°TÄ°Å: Yeni BÃ¶lÃ¼m ---
                        
        return details

    except requests.exceptions.RequestException as e:
        st.error(f"Ä°lana ulaÅŸÄ±lamadÄ±. Sahibinden.com eriÅŸimi engellemiÅŸ olabilir veya link hatalÄ±. Hata: {e}")
        return None
    except Exception as e:
        st.error(f"Veri ayrÄ±ÅŸtÄ±rÄ±lÄ±rken bir hata oluÅŸtu: {e}")
        return None

# --- Streamlit ArayÃ¼zÃ¼ ---

st.set_page_config(layout="wide", page_title="Sahibinden Ä°lan YardÄ±mcÄ±sÄ±")

st.title("ğŸš— Sahibinden Ä°lan YardÄ±mcÄ±sÄ±")
st.markdown("---")

st.info(
    "**Ã–NEMLÄ° UYARI:** Bu uygulama, satÄ±cÄ±nÄ±n ilana girdiÄŸi **beyanlarÄ±** (iÅŸaretlediÄŸi boya/deÄŸiÅŸen durumu) ve **ilan aÃ§Ä±klamasÄ±nÄ±** Ã§eker."
    "\n\nBu bilgiler satÄ±cÄ±nÄ±n kendi girdiÄŸi bilgilerdir, **resmi kayÄ±t DEÄÄ°LDÄ°R**."
    "\nResmi Hasar KaydÄ± (TRAMER) sorgusu iÃ§in plakayÄ± alÄ±p **5664**'e SMS atmanÄ±z (Ã¼cretli) gerekir."
)

st.markdown("### 1. AdÄ±m: Ä°lan Linkini YapÄ±ÅŸtÄ±rÄ±n")
url = st.text_input("Sahibinden.com araÃ§ ilanÄ±nÄ±n tam URL'sini buraya yapÄ±ÅŸtÄ±rÄ±n:", placeholder="https://www.sahibinden.com/ilan/...")

if st.button("Ä°lan Bilgilerini Getir", type="primary"):
    if not url or "sahibinden.com" not in url:
        st.warning("LÃ¼tfen geÃ§erli bir sahibinden.com ilanÄ± URL'si girin.")
    else:
        with st.spinner("Ä°lan bilgileri getiriliyor..."):
            details = fetch_ad_details(url)
            st.session_state.details = details # DetaylarÄ± oturumda sakla

if 'details' in st.session_state and st.session_state.details:
    details = st.session_state.details
    
    st.markdown("---")
    st.subheader("Ä°landan AlÄ±nan Bilgiler")
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric(label="Ä°lan BaÅŸlÄ±ÄŸÄ±", value=details['title'])
    with col2:
        st.metric(label="Fiyat", value=details['price'])

    # --- YENÄ° BÃ–LÃœM: SatÄ±cÄ± BeyanÄ± ---
    st.markdown("---")
    st.subheader("SatÄ±cÄ±nÄ±n Boya/DeÄŸiÅŸen BeyanÄ± (Ä°landa Ä°ÅŸaretledikleri)")
    
    col_boya, col_degisen = st.columns(2)
    
    with col_boya:
        st.write("ğŸ¨ **BoyalÄ± ParÃ§alar**")
        if details['painted'] and details['painted'][0] != "SatÄ±cÄ± tarafÄ±ndan belirtilmemiÅŸ.":
            # Liste olarak gÃ¶ster
            st.markdown('\n'.join(f'- {p}' for p in details['painted']))
        else:
            st.info("SatÄ±cÄ± boyalÄ± parÃ§a belirtmemiÅŸ.")
            
    with col_degisen:
        st.write("ğŸ› ï¸ **DeÄŸiÅŸen ParÃ§alar**")
        if details['replaced'] and details['replaced'][0] != "SatÄ±cÄ± tarafÄ±ndan belirtilmemiÅŸ.":
            # Liste olarak gÃ¶ster
            st.markdown('\n'.join(f'- {p}' for p in details['replaced']))
        else:
            st.info("SatÄ±cÄ± deÄŸiÅŸen parÃ§a belirtmemiÅŸ.")

    # --- YENÄ° BÃ–LÃœM: Ä°lan AÃ§Ä±klamasÄ± ---
    st.markdown("---")
    st.subheader("Ä°lan AÃ§Ä±klamasÄ± Analizi")
    
    desc_lower = details['description'].lower()
    # "kaydÄ±" kelimesini ekleyerek "hasar kaydÄ±" tamlamasÄ±nÄ± daha iyi yakalayabiliriz
    damage_keywords = ['tramer', 'hasar kaydÄ±', 'hasar', 'kaydÄ±', 'boyalÄ±', 'deÄŸiÅŸen', 'lokal', 'Ã§izik', 'kaza', 'boya', 'deÄŸiÅŸim']
    # Tekrar eden kelimeleri kaldÄ±r
    found_keywords = sorted(list(set([k for k in damage_keywords if k in desc_lower])))
    
    if found_keywords:
        st.write("**AÃ§Ä±klamada Bulunan Hasar/Boya Ä°lgili Anahtar Kelimeler:**")
        # Kelimeleri daha okunaklÄ± gÃ¶ster
        st.warning(f"`{', '.join(found_keywords)}`")
    else:
        st.success("**AÃ§Ä±klamada Hasar Belirten Anahtar Kelime BulunmadÄ±.**")
        
    with st.expander("AÃ§Ä±klamanÄ±n tamamÄ±nÄ± gÃ¶rmek iÃ§in tÄ±klayÄ±n..."):
        st.info(details['description'])


    st.markdown("---")
    st.markdown("### 2. AdÄ±m: Resmi Hasar KaydÄ± (TRAMER) Sorgusu")
    st.write("YukarÄ±daki bilgiler satÄ±cÄ±nÄ±n beyanÄ±dÄ±r. DoÄŸrulamak iÃ§in 5664'e SMS gÃ¶nderebilirsiniz.")

    plate_to_query = None

    if details['plate']:
        st.success(f"**Plaka ilanda bulundu:** {details['plate']}")
        plate_to_query = details['plate']
    else:
        st.warning("Plaka ilanda bulunamadÄ±, gizlenmiÅŸ veya 'BelirtilmemiÅŸ' olarak girilmiÅŸ.")
        st.write("LÃ¼tfen plakayÄ± ilandaki fotoÄŸraflardan veya satÄ±cÄ±dan alarak aÅŸaÄŸÄ±daki kutuya manuel girin.")
        
    manual_plate = st.text_input("PlakayÄ± Girin (BitiÅŸik, Ã¶rn: 34ABC1234)", 
                                 value=details['plate'] if details['plate'] else "",
                                 help="PlakayÄ± bitiÅŸik olarak yazÄ±n.")
                                 
    if manual_plate:
        plate_to_query = re.sub(r'\s+', '', manual_plate).upper()

    if plate_to_query:
        st.markdown("---")
        st.subheader("HazÄ±r SMS Metni")
        st.write("AÅŸaÄŸÄ±daki metnin tamamÄ±nÄ± kopyalayÄ±p telefonunuzdan **5664**'e SMS olarak gÃ¶nderin (Ãœcretlidir).")
        
        st.code(f"DETAY {plate_to_query}", language=None)
        
        st.write("DiÄŸer sorgu tÃ¼rleri:")
        st.code(f"PARCA {plate_to_query} [Tarih (gg/aa/yyyy)]", language=None)
        st.code(f"SASENO [Åasi NumarasÄ±]", language=None)

